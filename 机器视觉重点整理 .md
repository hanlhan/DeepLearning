# 机器视觉重点整理

> 来源：  [https://zhuanlan.zhihu.com/p/403226000](https://zhuanlan.zhihu.com/p/403226000)

> 本文使用 Zhihu On VSCode 创作并发布

本文为笔者大二时期机器视觉课程的重点内容归纳，如有纰漏请随时联系笔者。

## 数字图像的概念与性质

### 距离

### 距离种类

- 欧氏距离：$D_E=\sqrt{(m-h)^2+(n-k)^2}$
- 城区距离：$D_4= |m − h| + |n − k|$
- 棋盘距离：$D_8 = max {|m − h|,|n − k|}$

### 距离变换

给出图像中每个像素与某个图像子集的距离，算法如下：

1. 从上到下，从左至右遍历， $F(p)=\underset{q\in AL}{\min}\{F(p),D(p,q)+F(q)\}$
2. 从下到上，从右到左遍历，$F(p)=\underset{q\in BR}{\min}\{F(p),D(p,q)+F(q)\}$

```python
import numpy as np
def distanceTransform(img):
    # 默认传入参数为二值图，子集为0，其余为无穷大(255)
    result = img.copy()
    rows, cols = result.shape
    AL = np.array([[-1, 0], [-1, -1], [0, -1], [1, -1]])
    BR = np.array([[1, 0], [1, 1], [0, 1], [-1, 1]])
    for col in range(cols):
        for row in range(rows):
            for next in AL:
                [next_row, next_col] = [row, col] + next
                if 0 <= next_row < rows and 0 <= next_col < cols:
                    if result[next_row, next_col]+abs(row-next_row)+abs(col-next_col) < result[row, col]:
                        result[row, col] = result[next_row, next_col]+abs(row-next_row)+abs(col-next_col)
    for col in range(cols-1, -1, -1):
        for row in range(rows-1, -1, -1):
            for next in BR:
                [next_row, next_col] = [row, col] + next
                if 0 <= next_row < rows and 0 <= next_col < cols:
                    if result[next_row, next_col]+abs(row-next_row)+abs(col-next_col) < result[row, col]:
                        result[row, col] = result[next_row, next_col]+abs(row-next_row)+abs(col-next_col)
    return result
```

### 边缘与边界

- 边缘：像素与其直接邻接的**局部性质**，是图像上亮度的不连续点，是矢量。**方向与梯度垂直，大小与梯度相等。**
- 边界是与区域有关的**全局概念**

### 噪声

- 加性噪声：噪声与图像信号无关
- 乘性噪声：噪声幅值与信号本身幅值有关

### 卷积

- 卷积定义：
$$\begin{aligned}g(x,y)&=f(x,y)*h(x,y)\\&=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}f(x-a,y-b)h(a,b)dadb\end{aligned}$$
- 若系统响应可以表示成卷积的形式，则该系统是一个线性移不变系统；
任意线性移不变系统可以表示成卷积形式
- 离散卷积：
$$\begin{aligned} g(m,n)&=\sum_{k=0}^{M_2-1}\sum_{l=0}^{N_2-1}f(m-k,n-l)h(k,l)\\ &=\sum_{k=0}^{M_1-1}\sum_{l=0}^{N_1-1}f(k,l)h(m-k,n-l) \end{aligned}$$

其中$f(x, y)$尺寸是$M_1 × N_1$，$h(x, y)$尺寸是$M_2 × N_2$
卷积后尺寸为高为$M_1 + M_2 − 1$，宽为$N_1 + N_2 − 1$

## 图像预处理

### 像素亮度变换

- 亮度校正：**与像素位置相关**
- 灰度级变换：**与像素位置无关**，将原来在范围$[p_0,p_k]$内的亮度p变换为$[q_0,q_k]$内的亮度$q=T(p)$。

典型灰度级变换方法：

1. 底片变换
2. 分段增强
3. 图像二值化
- 直方图均衡化：创建一副在整个亮度范围内有**相同亮度分布**的图像，增强靠近直方图极大值附近的亮度对比度，减小了极小值附近的对比度。
$\begin{aligned} \int_{p_0}^pH(s)ds&=\int_{q_0}^q\frac{MN}{q_k-q_0}ds=\frac{MN(q-q_0)}{q_k-q_0}\\ q&=\frac{q_k-q_0}{MN}\int_{p_0}^pH(s)ds+q_0\\ q&=\frac{q_k-q_0}{MN}\sum_{s=p_0}^pH(s)+q_0 \end{aligned}$

在实际应用中$[p_0,p_k],[q_0,q_k]$一般固定为[0, 255]，则

$q=\frac{255}{MN}\sum_{s=0}^pH(s)$

```python
def hist_equal(img):
    rows, cols = img.shape
    S = rows * cols * 1.0
    hist = cv2.calcHist([img], [0], None, [256], [0, 256])
    cum_hist = np.cumsum(hist)
    T = np.zeros(256)
    out = np.zeros_like(img)
    for i in range(256):
        T[i] = np.round(255.0/S * cum_hist[i])
    for row in range(rows):
        for col in range(cols):
            out[row, col] = T[img[row, col]]
    out = cv2.convertScaleAbs(out)
    return out
```

### 几何变换

### 图像坐标变换

- 双线性变换（需要四个对应点对）
- 仿射变换（需要三个对应点对）

### 亮度插值

确定对应于输出图像离散栅格点在**输入图像**中点，对**输入图像**进行亮度插值

- 利用插值核对原图像进行卷积运算
- 最近邻插值：$f^{'}(x,y)=f(round(x),round(y))$
- 亮度插值：考虑四个相邻点，假设亮度线性。**减轻最近邻插值中出现的阶梯状直边界**
- 双三次插值：考虑16个相邻点，解决了**阶梯状边缘问题**和**模糊问题**，较好地保持了图像细节

### 局部预处理

### 线性滤波

- 均值滤波：多次采集相同静态景物获得平均图像，噪声均值为0，标准差为$\frac{\sigma}{\sqrt{k}}$。如果就一张，则局部邻域平均滤波。
- 高斯滤波：基于高斯函数形成卷积核，便于**去除服从正态分布的噪声**

### 非线性滤波

仅使用邻域中与被处理像素有**类似性质**的点进行平滑

- 设定非法数据范围$[\min,\max]$，只有在该范围内的像素值会被**有效邻域的平均**替代。掩膜为：

$\begin{aligned} h(i,j)=\left\{   \begin{aligned}   &1\quad f(m+i,n+j)\not\in[\min,\max]\\   &0\quad other   \end{aligned} \right. \end{aligned}$

- 根据反梯度的平均

$\delta(i,j)=\frac{1}{|f(m,n)-f(i,j)|}$

其中如果$f(m,n)=f(i,j)$则$\delta(i,j)=2$；$(m,n)$为掩膜中心
加权系数：
$\begin{aligned} \delta=\left\{     \begin{aligned}     &0.5 \quad 掩膜中心\\     &0.5\frac{\delta(i,j)}{\sum\delta(i,j)}\quad 非掩膜中心     \end{aligned} \right. \end{aligned}$

**区域像素比边缘像素权重更大**

- 旋转掩膜平均

![https://pic3.zhimg.com/v2-389edd501e5f8fd25ae99fa12ee0ac7a_b.png](https://pic3.zhimg.com/v2-389edd501e5f8fd25ae99fa12ee0ac7a_b.png)

旋转掩膜

计算该像素点在不同掩膜$h$中的方差：

$\sigma^2=\frac{1}{n}\{\sum_{(i,j)\in h}[f(i,j)-\frac{1}{n}\sum_{(i,j)\in h}f(i,j)]^2\}$

选择方差$\sigma^2$最小的掩膜，其均值即为该像素点最终结果

- 中值滤波：用像素邻域灰度值的中值代替该像素的灰度值,**便于去除脉冲噪声、椒盐噪声**
1. 确定掩膜中心和掩膜大小
2. 将掩膜内像素按亮度值大小排序
3. 取中值，若为偶数则取中间两个的均值

### 边缘检测

1. 设计平滑滤波器$h$，计算$h',h''$
2. 检测$f*h'$局部最大值或者$f*h''$过零点
- 平滑滤波器特点:
    - $\lim\limits_{|x|\to \infty}h(x)=0$
    - h(x)为偶函数
    - $\int_{-\infty}^{\infty}h(x)dx=1$，**保证滤波后不改变原信号的均值**
    - 一阶二阶可微
- 常见算子
    - Robert

        $$h_1=\begin{bmatrix}   -1 & 0 \\   0 & 1 \\   \end{bmatrix},   h_2=\begin{bmatrix}   0 & -1 \\   1 & 0 \\   \end{bmatrix}$$

    - Prewitt

        $$h_1=\begin{bmatrix}   -1 & -1 & -1 \\   0 & 0 & 0 \\   1 & 1 & 1   \end{bmatrix},   h_2=\begin{bmatrix}   -1 & 0 & 1 \\   -1 & 0 & 1 \\   -1 & 0 & 1   \end{bmatrix}$$

    - Sobel

        $$h_1=\begin{bmatrix}   -1 & -2 & -1 \\   0 & 0 & 0 \\   1 & 2 & 1   \end{bmatrix},   h_2=\begin{bmatrix}   -1 & 0 & 1 \\   -2 & 0 & 2 \\   -1 & 0 & 1   \end{bmatrix}$$

    - Laplacian

        $$h=\begin{bmatrix}   0 & 1 & 0 \\   1 & -4 & 1 \\   0 & 1 & 0   \end{bmatrix}$$

```python
def Robert_detection(img, threshold=-1):
    kernel1 = np.array([[-1, 0], [0, 1]])
    kernel2 = np.array([[0, -1], [1, 0]])
    img1 = cv2.filter2D(img, cv2.CV_32F, kernel1)   # 获取-45°方向的偏导
    img2 = cv2.filter2D(img, cv2.CV_32F, kernel2)   # 获取-135°方向的偏导
    mag = cv2.magnitude(img1, img2)
    mag = cv2.convertScaleAbs(mag)
    if threshold == -1:                             # 如果没有给定阈值则通过Otsu二值化
        _, mag = cv2.threshold(mag, 0, 255, cv2.THRESH_OTSU)
    else:
        mag[mag >= threshold] = 255
        mag[mag < threshold] = 0
    return mag

def Sobel_detection(img, threshold=-1):
    dx = cv2.Sobel(img, cv2.CV_32F, 1, 0)           # 获取水平方向的偏导
    dy = cv2.Sobel(img, cv2.CV_32F, 0, 1)           # 获取竖直方向的偏导
    mag = cv2.magnitude(dx, dy)
    mag = cv2.convertScaleAbs(mag)
    if threshold == -1:
        _, mag = cv2.threshold(mag, 0, 255, cv2.THRESH_OTSU)
    else:
        mag[mag >= threshold] = 255
        mag[mag < threshold] = 0
    return mag

def Prewitt_detection(img, threshold=-1):
    kernel1 = np.array([[-1, -1, -1], [0, 0, 0], [1, 1, 1]])
    kernel2 = np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]])
    dx = cv2.filter2D(img, cv2.CV_32F, kernel2)
    dy = cv2.filter2D(img, cv2.CV_32F, kernel1)
    mag = cv2.magnitude(dx, dy)
    mag = cv2.convertScaleAbs(mag)
    if threshold == -1:
        _, mag = cv2.threshold(mag, 0, 255, cv2.THRESH_OTSU)
    else:
        mag[mag >= threshold] = 255
        mag[mag < threshold] = 0
    return mag

def Laplacian_detection(img, threshold=-1):
    out = cv2.Laplacian(img, cv2.CV_32F, ksize=3)
    out = cv2.convertScaleAbs(out)
    if threshold == -1:
        _, out = cv2.threshold(out, 0, 255, cv2.THRESH_OTSU)
    else:
        out[out >= threshold] = 255
        out[out < threshold] = 0
    return out
```

- $\sigma$越大，图像分辨率越低
- Canny边缘检测
1. 与二维高斯函数做卷积，**消除噪声**
2. 计算每个像素的梯度大小和方向
3. 根据梯度方向，作非极大值抑制获取边缘位置
3.1. 遍历非0梯度的像素，根据梯度方向找到两个邻接像素
3.2. 若存在一个邻接像素梯度幅值大于该像素，则将该像素置零**注：在实际运用中邻接像素的幅值通过线性插值获得**
4. 滞后阈值化处理/双阈值法
4.1. 设置高低阈值
4.2. 超过高阈值的设为边缘，弱于低阈值的舍弃
4.3. 遍历处于高低阈值区间内的像素，若该像素与边缘邻接则标记为边缘
- 多尺度特征综合
1. 标记最小尺度的边缘
2. 高斯卷积后估计大尺度检测边缘位置（大尺度合成边缘响应）
3. 大尺度滤波器检测（大尺度实际边缘响应）
4. 实际边缘响应显著强于合成边缘响应，则接受此边缘点

### 图像复原

- 图像增强：使图像具有更好的视觉效果
- 图像复原：利用图像降质过程的先验知识建立**降质模型**，是降质的逆过程
- 逆滤波：退化函数已知，通过复原滤波器消除退化。适用于**没有被噪声污染**的情况
$\begin{aligned} g(x,y)&=H[f(x,y)]+n(x,y)\\ g(x,y)&=h(x,y)*f(x,y)+n(x,y)\\ G(u,v)&=H(u,v)F(u,v)+N(u,v)\\ F(u,v)&=G(u,v)H^{-1}(u,v)-N(u,v)H^{-1}(u,v) \end{aligned}$

$H$为退化函数，$n$为加性噪声，根据线性移不变性质可化为卷积形式(2)，再进行傅里叶变换(3)

- 维纳滤波：寻找使均方误差最小的估计*f̂*

## 图像分割

### 阈值化

- p率阈值化：基于直方图选择阈值*T*，使得$\frac{1}{p}$的像素灰度值比*T*小
- 模式方法：寻找直方图两个局部极大值，取它们之间的极小值为阈值
- 最优阈值化：
1. 设定初始阈值$t_0$
2. 计算灰度值小于$t_0$的像素集合的平均值$\mu_1$，灰度值大于$t_0$的像素集合的平均值$\mu_2$
3. 新阈值$t_1=\frac{\mu_1+\mu_2}{2}$
4. 重复步骤2、3直到阈值变化足够小
- **OTSU阈值检测**：
1. 将直方图除以像素总数，进行归一化，得到像素概率分布直方图*H*
2. 划分背景*B*（灰度值小于等于*t*的像素）与前景*F*（灰度值大于*t*的像素）
3. 背景、前景概率和均值计算：

$$\begin{aligned}   \omega_B(t)&=\sum_{i=0}^tH(i)\\   \omega_F(t)&=\sum_{i=t+1}^{255}H(i)\\   \mu_B(t)&=\sum_{i=0}^t\frac{iH(i)}{\omega_B}\\   \mu_F(t)&=\sum_{i=t+1}^{255}\frac{iH(i)}{\omega_F}\\   \mu&=\sum_{i=0}^{255}iH(i)   \end{aligned}$$

1. 计算类间方差:

$$\sigma(t)=\omega_B(t)(\mu_B(t)-\mu)^2+\omega_F(t)(\mu_F(t)-\mu)^2$$

1. 最优阈值 $\hat t=\underset{t}{\arg \max}(\sigma(t))$

```python
def Otsu(img):
    # 获取直方图并归一化
    hist = cv2.calcHist([img], [0], None, [256], [0, 256])[:, 0]
    hist /= np.sum(hist)
    # 取直方图中非零索引
    nonzero_index = np.nonzero(hist)[0]
    # min_index和max_index代表灰度级的最低值与最高值
    [min_index, max_index] = nonzero_index[[0, -1]]
    # sigma存储以各非零索引的灰度级作为阈值的类间方差
    sigma = np.zeros_like(nonzero_index)
    for i in range(len(nonzero_index)):
        t = nonzero_index[i]
        # 根据阈值t将直方图划分为两部分
        before = hist[min_index:t + 1]
        after = hist[t + 1:max_index + 1]
        # 计算两部分的概率
        P_before = np.sum(before)
        P_after = np.sum(after)
        # 计算三种均值
        miu_before = np.sum(np.arange(min_index, t + 1) * before / P_before)
        miu_after = np.sum(np.arange(t + 1, max_index + 1) * after / P_after)
        miu = np.sum(np.arange(min_index, max_index + 1) * hist[min_index: max_index + 1])
        # 计算此时的类间方差
        sigma[i] = P_before * (miu_before - miu) ** 2 + P_after * (miu_after - miu) ** 2
    # 取sigma最大的索引就可以读取出对应阈值
    threshold = nonzero_index[np.argmax(sigma)]
    Binary = img.copy()
    Binary[img >= threshold] = 255
    Binary[img < threshold] = 0
    return Binary
```

### 边界跟踪

### 内边界跟踪

1. 从左上方开始搜索，设定$dir=3(4-邻接)/7(8-邻接)$
2. 按逆时针方向搜索$3\times 3$邻域，初始方向为:
$\begin{aligned} 4-邻接跟踪：&dir=(dir+3)\mod 4\\ 8-邻接跟踪：&dir=(dir+7)\mod 8（dir为偶数）\\ &dir=(dir+6)\mod 8（dir为奇数） \end{aligned}$

**简单来说对于4邻接跟踪，更新后的*dir*为之前的$dir − 1$（顺时针转45°）；对于8邻接跟踪，更新后的$dir$为之前的$dir$顺时针转至第一个奇数位**例如：4邻接$dir = 3$，更新后的$dir=2$；8邻接$dir = 6或7$，更新后的$dir=5$
3. 当前像素等于第二个像素，且上一个像素等于第一个像素时停止；否则重复步骤2

```python
def InnerTrack(img):
    # 生成对应边界矩阵
    output = np.zeros_like(img)
    # 8×2的矩阵表示各方向下的移动情况
    steps = np.array([[0, 1], [-1, 1], [-1, 0], [-1, -1],
                     [0, -1], [1, -1], [1, 0], [1, 1]])
    rows, cols = img.shape
    for row in range(rows):
        for col in range(cols):
            # 当原图中该点亮度不为0（即白色背景），或边界图像为255（即该点已经处理过），或以该点为中心的3×3边界矩阵有大于0的（该点附近有处理过的边界）
            # 或以该点为中心的3×3原图矩阵均为0（即目标图像中心区域）——这四种情况发生时都要略过
            if img[row, col] != 0 or output[row, col] == 255 or np.sum(output[row-1:row+2, col-1:col+2]) > 0 or np.sum(img[row-1:row+2, col-1:col+2]) == 0:
                continue
            next_pos = [row, col]
            next_dir = 7
            while next_pos:
                next_pos, next_dir = Track(img, output, next_pos, next_dir, steps)
    return output

def Track(img, output, pos, dir, steps):
    # 设定初始方位
    dir = (dir + 6) % 8 if dir % 2 else (dir + 7) % 8
    # 将初始点标记
    output[pos[0], pos[1]] = 255
    # 遍历各方向
    for i in range(8):
        next_dir = (dir + i) % 8
        # 确定下一步的方位
        [row, col] = pos + steps[next_dir]
        # 只有当下一步没越界并且原图中该点是黑色时继续处理
        if 0 <= row < img.shape[0] and 0 <= col < img.shape[1] and img[row, col] == 0:
            # 如果这时边界矩阵仍是0，表示没被处理过，可以继续处理
            if output[row, col] == 0:
                # 返回下一步的位置和方向
                return [row, col], next_dir
            # 如果处理过直接结束，内边界跟踪结束
            return None, None
    return None, None
```

### 外边界跟踪

1. 进行4邻接跟踪
2. 搜索过程中**测试过的非内边界像素**组成外边界

### 扩展边界

![https://pic4.zhimg.com/v2-9429edb298888da2c9d838a9ba4b2853_b.png](https://pic4.zhimg.com/v2-9429edb298888da2c9d838a9ba4b2853_b.png)

扩展边界

- 边界形状与内边界完全相同，像素位置向下和向右平移了半个像素
- 对于内边界而言：扩展边界为内边界的上、左像素；右像素的右方、下方像素；下像素的下方、右方像素
- 对于外边界而言：扩展边界为上像素向右下移动1个像素；左像素向右移动1个像素；右像素向下移动1个像素
- 查找表法追踪边界：按照12种情况的表进行追踪

![https://pic3.zhimg.com/v2-dbff05faafafcce734843534aaf8199e_b.png](https://pic3.zhimg.com/v2-dbff05faafafcce734843534aaf8199e_b.png)

查找表

### 基于区域分割

- 分裂与归并：
    1. 金字塔数据结构种，任意区域不符合一致性测试，则分裂成四个子区域；如果具有相同父结点的四个区域具有一致性，则归并
    2. 执行步骤1至无法分裂与归并
    3. 归并任意两个具有一致性的邻接区域（可没有相同父结点）
    4. 如果必须删除小尺寸，则归并小区域和最相似的邻接区域
- 一致性规则可自定义，例如天鹅星座环的X射线频段图像中，需要分割出稀疏环（标准差较大且灰度值介于背景和中心区域之间）。此时可定义为一致性为$\sigma>10, 0<mean<125$.

### 分水岭分割

对于梯度幅值图像而言，盆地表示原图像平滑的地方。给定幅值初始值的情况下，每个幅值小于初始值的盆地表示一个区域。按照幅值大小从初始值往上遍历，对于新像素而言它将**分给离它邻接的盆地**。如果**它和两个盆地都邻接**，则为**分水岭**。如果它**没有邻接盆地**，则为**新盆地**。

## 数学形态学

### 二值图像形态学

- 反射：$\hat B=\{(-x,-y)|(x,y)\in B\}$
- 平移：$(B)_z=\{c|c=b+z, b\in B\}$
- 膨胀：$A\oplus B=\{z|(\hat B)_z\cap A \neq \varnothing\}$
- 腐蚀：$A\otimes B=\{z|(B)_z\subseteq A\}$
- 对偶性：
$(A\circleddash B)^c=A^c\oplus \hat B\\ (A\oplus B)^c=A^c\circleddash \hat B$

**对于原点对称结构元来说，对*A*背景膨胀的补集等于对*A*的腐蚀**

- 击中击不中变换：$A\otimes B=(A\circleddash B_1\cap A^c\circleddash B_2)$，其中*B*为与目标匹配的模板，*B*为与目标背景匹配的模板。**用于在A中寻找与模板B匹配的元素**
- 开运算：$A\circ B=(A\circleddash B)\oplus B$，**平滑物体轮廓，断开狭颈，去掉细小突出**
- 闭运算：$A\bullet B=(A\oplus B)\circleddash B$，**平滑物体轮廓，弥合较窄间断和细长沟壑，消除小孔，填补轮廓线中的断裂**

**膨胀运算的例子**：
结构元反射后，根据*$A$中元素**坐标对$\hat B$平移，若平移后的$(\hat B)_z$与$A$仍有交集则该元素属于膨胀结果集合

![https://pic2.zhimg.com/v2-a75f8bd37420a922a98ab165c3845009_b.png](https://pic2.zhimg.com/v2-a75f8bd37420a922a98ab165c3845009_b.png)

膨胀

如上图所示，$A$的原点在左下角。(0, 0)坐标的变换结果$(\hat B)_z=\{(-1,0),(0,0)\}$与*A*不相交，所以$(0,0)\not\in A\oplus B$。
而对于$(1, 4)$坐标的变换结果$(\hat B)_z=\{(0,4),(1,4)\}$与*A*相交，则(1, 4) ∈ *A* ⊕ *B*。

## 特征检测

### 角点检测

- 角点是在邻域内的各个方向上灰度变化值足够高的点
- 角点是图像边缘曲线上曲率极大值的点
- 角点检测的准则：
    - 角点检测的正确性：不检测出错的角点
    - 角点定位的准确性：位置不能有过大的偏差
    - 角点检测算法稳定性与效率：受噪音影响小

### Moravec角点检测：任意方向移动窗口，若窗口内灰度值都有剧烈变化则窗口中心为角点

- 变化值：$E(\Delta x, \Delta y)=\sum w(x_i,y_i)[I(x_i,y_i)-I(x_i+\Delta x,y_i+\Delta y)]^2$，取$(\Delta x, \Delta y)取(1,0),(1,1),(0,1),(-1,1)$

![https://pic1.zhimg.com/v2-96d9e20945948b31990781889e299290_b.png](https://pic1.zhimg.com/v2-96d9e20945948b31990781889e299290_b.png)

移动方向

- 角点响应函数$R(x_i, y_i)=\min{E(\Delta x, \Delta y)}$
- 将响应函数中低于阈值的值设为0
- 非极大值抑制：遍历角点响应函数，若角点响应在窗口内不是最大则置0
- 选择非零点作为角点检测结果

### Harris角点检测：使用高斯函数作为窗口

$\begin{aligned} E(\Delta x, \Delta y)=&\sum w(x_i,y_i)[I(x_i+\Delta x,y_i+\Delta y)-I(x_i,y_i)]^2\\ =&\sum w(x_i,y_i)[I(x_i,y_i)+\Delta xI_x+\Delta yI_y-I(x_i,y_i)]^2\\ =&\sum w(x_i,y_i)[\Delta x\quad \Delta y] \begin{bmatrix} I_x^2 & I_xI_y\\ I_xI_y & I_y^2 \end{bmatrix} \begin{bmatrix} \Delta x\\ \Delta y \end{bmatrix}\\ =&[\Delta x\quad \Delta y]\sum w(x_i,y_i) \begin{bmatrix} I_x^2 & I_xI_y\\ I_xI_y & I_y^2 \end{bmatrix} \begin{bmatrix} \Delta x\\ \Delta y \end{bmatrix}\\ =&[\Delta x\quad \Delta y]M \begin{bmatrix} \Delta x\\ \Delta y \end{bmatrix}\\ \end{aligned}$

- 自相关矩阵M的响应函数$R=det(M)-k(trace(M))^2$

![https://pic2.zhimg.com/v2-52998fb18f303b68a9d667b01399be49_b.png](https://pic2.zhimg.com/v2-52998fb18f303b68a9d667b01399be49_b.png)

特征值关系与响应函数

### SIFT

1. 检测尺度空间的极值点
2. 精确定位特征点(Keypoint)
- 去除不稳定极值点
- 去除边缘响应过大的极值点：计算差分图像D的Hessian矩阵

$$\bold H=\begin{bmatrix} D_{xx} & D_{xy}\\ D_{xy} & D_{yy} \end{bmatrix}$$
满足 
$$\frac{trace(\bold H)^2}{det(\bold H)}<\frac{(r+1)^2}{r},r=10$$

1. 设定特征点的方向参数
- 在高斯尺度空间计算像素梯度

$$m(x,y)=\sqrt{[L(x+1,y)-L(x-1,y)]^2+[L(x,y+1)-L(x,y-1)]^2}\\ \theta(x,y)=\arctan\frac{L(x,y+1)-L(x,y-1)}{L(x+1,y)-L(x-1,y)}$$

- 建立梯度方向直方图，横轴为角度，范围0~360°
- 直方图峰值对应的方向为**主方向**
- 能量超过主峰值80%的次峰对应的方向为**辅方向**
1. 生成特征点的描述子（**128维向量**）
- 将坐标轴方向旋转至特征点的方向
- 对每个特征点为中心取窗口，**高斯加权**增强特征点附近的像素的贡献
- 将窗口分为4 × 4的小块，每块计算8个方向的梯度方向直方图
- 每个特征点用4 × 4 × 8维向量描述

### SURF

特征点描述子为**64维**

### 特征点匹配

- 特征点的数据结构包含：
    - 位置坐标
    - 尺度
    - 方向
    - 特征向量
- 根据特征向量欧氏距离找出最近邻和次近邻，如果最近邻比次近邻小于阈值，则匹配成功

### HOG

- 通过**局部梯度、边缘方向分布**描述局部目标，而不需要知道对应的梯度、边缘的位置
1. 图像归一化
    - 灰度化
    - 归一化：gamma校正降低图像局部的阴影和光照变化所造成的影响
2. 计算图像梯度
    - 计算无符号的梯度方向
        $\begin{aligned}     \theta(x,y)=\left\{     \begin{aligned}     &\theta(x,y)+\pi\quad \theta(x,y)<0\\     &\theta(x,y)\quad others     \end{aligned}     \right.     \end{aligned}$
3. 在细胞单元构建梯度直方图
    - 将细胞单元内每个像素按照方向划分成9块
    - 按照方向将幅值划分到不同的块：比如165度方向上的幅值为85，则
    $160度方向上分配：85\times \frac{180-165}{20}=63.75\\ 0度方向上分配：85\times \frac{165-160}{20}=21.25$
4. 块内梯度直方图对比度归一化
    - 按照二范数进行归一化
5. 计算HOG特征描述子
    - *特征向量长度* = 9 × *块内细胞数* × *图像内块数*

### Hough变换

- $点\rightarrow 线$

$$y_i=ax_i+b\rightarrow b=-x_ia+y_i(x_i,y_i固定)$$

- $线\rightarrow 点$
 $(x_i,y_i),(x_j,y_j)在直线y=ax+b上\\ 则有 \left\{   \begin{aligned}   b=-x_ia+y_i\\   b=-x_ja+y_j   \end{aligned} \right.$
- $线\rightarrow 正弦曲线交点$
 $(x_i,y_i),(x_j,y_j)在直线\rho=x\cos\theta+y\sin\theta上\\ 则有 \left\{   \begin{aligned}   \rho=x_i\cos\theta+y_i\sin\theta\\   \rho=x_j\cos\theta+y_j\sin\theta   \end{aligned} \right.$
1. 设定参数空间为*m* × *n*个累加单元，设置累加器矩阵Q并置零
2. 对于XY平面上的点$(x_i，y_i)$，令$\theta$等于$\theta$轴上所有允许的细分值，计算对应的$\rho=x_i\cos\theta+y_i\sin\theta$。（根据一个点在参数空间画出一条正弦曲线）
3. 将*ρ*四舍五入成最接近的细分值
4. 在Q中找出对应单元加1
5. 重复2-4步，最终Q值最大的单元对应的*θ*, *ρ*即为直线方程参数

- 直线检测的精度取决于两个参数细分值的大小
- 如果参数空间细分过粗，则参数的凝聚效果较差，找不出直线对应的准确参数
- 细分值也不能过小，会增大算法第2步的计算量



## 立体视觉

- **立体视觉：由多幅图像获取物体的三维几何信息**
- 基本步骤：
    - 摄像机标定
    - 多幅图像中建立对应点对
    - 重构场景中的三维坐标

### 摄像机标定

- 姿态描述：在物体上固定一个坐标系{B}，给出此坐标系相对于参考坐标系{A}的表达
- 位姿描述：在三维空间中表示物体的位置和姿态
- 过渡坐标系：将坐标变换分解为旋转、平移；过度坐标系的姿态和A相同，原点和B重合
 $$\begin{aligned} ^CP&={_B^AR}^BP\\ ^AP&={^CP}+^AP_{OB}\\ ^AP&={_B^AR}^BP+^AP_{OB} \end{aligned}$$
- 旋转矩阵
    - 绕x轴顺时针旋转*θ*：

        $$R=\begin{bmatrix}   1 & 0 & 0 \\   0 & \cos\theta & -\sin\theta \\   0 & \sin\theta & \cos\theta   \end{bmatrix}$$

- 绕y轴顺时针旋转*θ*：

    $$R=\begin{bmatrix}   \cos\theta & 0 & \sin\theta \\   0 & 1 & 0 \\   -\sin\theta & 0 & \cos\theta   \end{bmatrix}$$

- 绕z轴顺时针旋转*θ*：
  $$R=\begin{bmatrix}   \cos\theta & -\sin\theta & 0\\   \sin\theta & \cos\theta & 0\\   0 & 0 & 1 \\   \end{bmatrix}$$
- 齐次坐标变换：
  $$R=\begin{bmatrix}   \cos\theta & 0 & \sin\theta \\   0 & 1 & 0 \\   -\sin\theta & 0 & \cos\theta   \end{bmatrix}$$
- 齐次变换矩阵
    $$_B^AT=\begin{bmatrix} {_B^AR} & ^AP_{OB}\\ 0 & 1\\ \end{bmatrix}$$
- 线性摄像机成像：世界坐标系-相机坐标系-物理单位表示的图像坐标系-像素单位表示的图像坐标系
    - 摄像机外参数：**6个独立外参**
    - 摄像机内参数：
        - u/v轴互相垂直：**4个独立内参**
        - u/v轴不垂直：**5个独立内参**
- 单透视摄像机成像：欧式世界坐标系-欧式相机坐标系-欧式图像坐标系-图像仿射坐标系
    - 透视投影矩阵M有11个自由参数，求解M需要6个对应点对
    - 参数模型的最优化估计
        - 最大似然概率估计
        - 线性估计
        - 叉积矩阵
        - 鲁棒估计
- 畸变与失真
    - 径向失真
        - 光线在远离透镜中心的地方比靠近中心的地方更弯曲
        - 对于径向失真，摄像机中心的畸变为零，随着向边缘移动，畸变越来越严重
- 切向失真
    - 由于透镜制造上的缺陷，使透镜本身与成像平面不平行
- 径向畸变只会导致径向失真
- 离心畸变、薄透镜畸变会导致径向、切向失真
- 直接线性变换DLT标注法：
    - 根据n个点对确定2n个方程

### 张正友平面标定法

- 将世界坐标系置于靶标平面，原点设在靶标的一角。其中$X_w,Y_w$方向沿靶标平面，$Z_w$方向垂直于靶标平面。
- 优点：
    1. 靶标平面上的点的世界坐标系坐标便于确定
    2. 靶标平面上的点的Z方向坐标恒为0，三维坐标只与$X_w,Y_w$有关，可以简化为二维坐标
- 步骤：
    1. 不考虑畸变，标定摄像机参数，得到参数的线性初值
    2. 利用线性初值，进行非线性标定，得到畸变参数
    3. 重复1和2，直至参数收敛
- 单应性矩阵给出从一个平面到另一个平面的映射，它包括摄像机内外参数矩阵
$$\begin{aligned} z_{ci} \begin{bmatrix} u_i\\ v_i\\ 1 \end{bmatrix} =& \begin{bmatrix} M_{in} & 0 \end{bmatrix} \begin{bmatrix} {_w^cR} & ^cP_{Ow}\\ 0 & 1\\ \end{bmatrix} \begin{bmatrix} x_{wi}\\ y_{wi}\\ z_{wi}\\ 1 \end{bmatrix}\\ =&H \begin{bmatrix} x_{wi}\\ y_{wi}\\ 1 \end{bmatrix} \end{aligned}$$
- 具体解法
    1. 保持相机位置不变，将标定板置于不同位置采集m幅图像，每个图像n个角点
    2. 遍历每幅图像，求解单应性矩阵初值（**2n个方程，9个未知数**）；再进行非线性优化，获取单应性矩阵
    3. 综合m幅图像的单应性矩阵，求解方程vb=0（**2m个方程，6个未知数**），将中间矩阵B分解，获取内参数矩阵（**5个参数**）
    4. 由H和$M_{in}$计算每幅图像的R和P
    5. 综合m幅图像中n个角点求解Ak=B（**2mn个方程，2个未知数**），得到畸变系数$k_1,k_2$
    6. 参数最优化：通过非线性最小二乘法优化内参数矩阵（**5个参数**），R和P（**6m个参数**），$k_1,k_2$

### 对极几何

- 基线：两个相机光心连线
- 极面：观察点P与两相机光心构成的平面
- 极线：图像$I_2$上对应于图像$I_1$中$p_1$点的极线——极面与$I_2$的交线/$O_1p_1$在$I_2$上的投影
- 对极约束：对应于图像*I*上的点*p*在图像*I*上的对应点一定落在图像*I*的极线上**作用：将$p_1$，$p_2$对应点的搜索空间的维度由2维降为1维**

![https://pic4.zhimg.com/v2-d4b06099576a30bc4b1de6434ea3db6f_b.png](https://pic4.zhimg.com/v2-d4b06099576a30bc4b1de6434ea3db6f_b.png)

对极约束

- 极点：所有极线交汇的那一点，也是$O_1O_2$连线与图像的交点，也是光心到另一图像的投影点
- 极线方程：

    $p_2^T[m]_\times M_{21}M_{11}^{-1}p_1=0$

若给定$p_1$则公式为关于$p_2$的线性方程，即图像*I*2上的极线方程；若给定$p_2$则同理。
其中对于三维向量$t=[t_x\quad t_y\quad t_z]^T$
  $$[t]_\times=\begin{bmatrix}   0 & -t_z & t_y\\   t_z & 0 & -t_x\\   -t_y & t_x & 0   \end{bmatrix}$$

且满足$t\times r=[t]_\times r$

- 基础矩阵:
$$F=[m]_\times M_{21}M_{11}^{-1}\\p_2^TFp_1=0$$

F由相机参数矩阵确定，若对应点已知，则F包含了从一对图像中可以恢复出的所有信息